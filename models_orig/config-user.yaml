TinyPixel_Llama-2-7B-bf16-sharded$:
  loader: Transformers
  cpu_memory: 0
  auto_devices: true
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  use_fast: false
  load_in_4bit: false
  compute_dtype: bfloat16
  quant_type: nf4
  use_double_quant: false
  disable_exllama: false
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 0
  gpu_memory_0: 0
openassistant-llama2-13b-orca-8k-3319.ggmlv3.q5_1.bin$:
  loader: ctransformers
  cpu: false
  threads: 0
  threads_batch: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 0
  tensor_split: ''
  n_ctx: 8192
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 0
  numa: false
  model_type: llama
stablebeluga-13b.ggmlv3.q4_1.bin$:
  loader: ctransformers
  model_type: llama
  threads: 0
  n_batch: 511
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
falcon-40b-Q5_K_M.gguf$:
  loader: ctransformers
  model_type: falcon
  threads: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 8192
ggml-gpt4all-l13b-snoozy.bin$:
  loader: ctransformers
  model_type: llama
  threads: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
wizardlm-13b-v1.0-uncensored.ggmlv3.q4_K_M.bin$:
  loader: ctransformers
  model_type: llama
  threads: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 4096
llama-2-7b-chat.gguf.q4_1.bin$:
  loader: ctransformers
  model_type: llama
  threads: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 4096
llama-2-13b-chat.gguf.q4_1.bin$:
  loader: llama.cpp
  model_type: llama
  threads: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 32768
  cpu: false
  threads_batch: 0
  mul_mat_q: false
  tensor_split: ''
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 0
  numa: false
llama-2-13b-guanaco-qlora.Q4_K_M.gguf$:
  loader: ctransformers
  model_type: llama
  threads: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 4096
RWKV_rwkv-raven-14b$:
  loader: Transformers
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  use_fast: true
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  disable_exllama: false
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 0
  gpu_memory_0: 0
llama-2-7b-32k-instruct.Q4_K_M.gguf$:
  loader: ctransformers
  cpu: false
  threads: 0
  threads_batch: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 0
  tensor_split: ''
  n_ctx: 32768
  llama_cpp_seed: 79.0
  compress_pos_emb: 8
  alpha_value: 1
  rope_freq_base: 0
  numa: false
  model_type: llama
codellama-34b-instruct.Q4_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  threads_batch: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 0
  tensor_split: ''
  n_ctx: 16384
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
  numa: false
mistral-7b-instruct-v0.1.Q4_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  threads_batch: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 0
  tensor_split: ''
  n_ctx: 8192
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 10000
  numa: false
zephyr-7b-alpha.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  threads_batch: 0
  n_batch: 521
  no_mmap: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 0
  tensor_split: ''
  n_ctx: 8192
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 10000
  numa: false
